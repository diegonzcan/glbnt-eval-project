{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "import configparser\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOG RESET\n",
    "if os.path.exists('std.log'):\n",
    "    os.remove('std.log')\n",
    "else: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='std.log',\n",
    "                    filemode='a',\n",
    "                    format='%(message)s',\n",
    "                    datefmt='%H:%M:%S',\n",
    "                    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../config.ini']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read(r'../../config.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA FILES\n",
    "jobs = 'jobs.csv'\n",
    "hired_employees = 'hired_employees.csv'\n",
    "departments = 'departments.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PATH\n",
    "data_path = config['PATHS']['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_range(data):\n",
    "    \"\"\"Gets data ranges for string and numerical columns and logs them to std.log file\n",
    "       We will use this to determine SQL table DDL \n",
    "     \"\"\"\n",
    "\n",
    "    for c in data.select_dtypes(include=['object']).columns:\n",
    "        max_length = data[c].apply(lambda x: len(str(x))).max()\n",
    "        min_length = data[c].apply(lambda x: len(str(x))).min()\n",
    "        logging.info(f'Column: {c}\\n Character range:{min_length} - {max_length} ')\n",
    "\n",
    "    for c in data.select_dtypes(include=['int64', 'float64']):\n",
    "        max = data[c].max()\n",
    "        min = data[c].min()\n",
    "        logging.info(f'Column: {c}\\n Numerical range:{min} - {max} ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = {\n",
    "    jobs: ['id','job'],\n",
    "    departments: ['id', 'department'],\n",
    "    hired_employees: ['id','name','datetime', 'department_id','job_id']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'job'], dtype='object')\n",
      "Index(['id', 'department'], dtype='object')\n",
      "Index(['id', 'name', 'datetime', 'department_id', 'job_id'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "for data_file, schema in data_files.items():\n",
    "    logging.info(f'{data_file}')\n",
    "    data = pd.read_csv(Path(data_path) / data_file, header=None, names=schema)  # we set the columns to the schema provided\n",
    "    print(data.columns)\n",
    "    get_data_range(data=data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
